# Copyright (c) 2024 PaddlePaddle Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


LOCALES = {
    "lang": {"en": {"label": "ğŸ·ï¸ Lang"}, "zh": {"label": "ğŸ·ï¸ è¯­è¨€"}},
    "model_tag": {"zh": "æ¨¡å‹", "en": "Model"},
    "image_tag": {"zh": "å›¾åƒ", "en": "Image"},
    "video_tag": {"zh": "è§†é¢‘", "en": "Video"},
    "question_tag": {"zh": "é—®é¢˜", "en": "Question"},
    "model_name": {"en": {"label": "ğŸ’ Model name"}, "zh": {"label": "ğŸ’ æ¨¡å‹åç§°"}},
    "model_path": {
        "en": {"label": "ğŸ“ Model path", "info": "Path to pretrained model or model identifier from Hugging Face."},
        "zh": {"label": "ğŸ“ æ¨¡å‹è·¯å¾„", "info": "æœ¬åœ°æ¨¡å‹çš„æ–‡ä»¶è·¯å¾„æˆ– Hugging Face çš„æ¨¡å‹æ ‡è¯†ç¬¦ã€‚"},
    },
    "finetuning_type": {"en": {"label": "ğŸ”§ Finetuning method"}, "zh": {"label": "ğŸ”§ å¾®è°ƒæ–¹æ³•"}},
    "checkpoint_path": {"en": {"label": "ğŸ—‚ï¸ Checkpoint path"}, "zh": {"label": "ğŸ—‚ï¸ æ£€æŸ¥ç‚¹è·¯å¾„"}},
    "template": {
        "en": {"label": "ğŸ“ Prompt template", "info": "The template used in constructing prompts."},
        "zh": {"label": "ğŸ“ æç¤ºæ¨¡æ¿", "info": "æ„å»ºæç¤ºè¯æ—¶ä½¿ç”¨çš„æ¨¡æ¿ã€‚"},
    },
    "rope_scaling": {"en": {"label": "RoPE scaling"}, "zh": {"label": "RoPE æ’å€¼æ–¹æ³•"}},
    "booster": {"en": {"label": "Booster"}, "zh": {"label": "åŠ é€Ÿæ–¹å¼"}},
    "training_stage": {
        "en": {"label": "âš™ï¸ Stage", "info": "The stage to perform in training."},
        "zh": {"label": "âš™ï¸ è®­ç»ƒé˜¶æ®µ", "info": "ç›®å‰é‡‡ç”¨çš„è®­ç»ƒæ–¹å¼ã€‚"},
    },
    "dataset_dir": {
        "en": {"label": "ğŸ’¾	Data dir", "info": "Path to the data directory."},
        "zh": {"label": "ğŸ’¾	æ•°æ®è·¯å¾„", "info": "æ•°æ®æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚"},
    },
    "dataset": {"en": {"label": "ğŸ“š	Dataset"}, "zh": {"label": "ğŸ“š æ•°æ®é›†"}},
    "data_preview_btn": {"en": {"value": "ğŸ” Preview dataset"}, "zh": {"value": "ğŸ” é¢„è§ˆæ•°æ®é›†"}},
    "preview_count": {"en": {"label": "Count"}, "zh": {"label": "æ•°é‡"}},
    "page_index": {"en": {"label": "Page"}, "zh": {"label": "é¡µæ•°"}},
    "prev_btn": {"en": {"value": "Prev"}, "zh": {"value": "ä¸Šä¸€é¡µ"}},
    "next_btn": {"en": {"value": "Next"}, "zh": {"value": "ä¸‹ä¸€é¡µ"}},
    "close_btn": {"en": {"value": "Close"}, "zh": {"value": "å…³é—­"}},
    "preview_samples": {"en": {"label": "Samples"}, "zh": {"label": "æ ·ä¾‹"}},
    "learning_rate": {
        "en": {"label": "âš–ï¸ Learning rate", "info": "Initial learning rate for AdamW."},
        "zh": {"label": "âš–ï¸ å­¦ä¹ ç‡", "info": "AdamW ä¼˜åŒ–å™¨çš„åˆå§‹å­¦ä¹ ç‡ã€‚"},
    },
    "num_train_epochs": {
        "en": {"label": "â³ Epochs", "info": "Total number of training epochs to perform."},
        "zh": {"label": "â³ è®­ç»ƒè½®æ•°", "info": "éœ€è¦æ‰§è¡Œçš„è®­ç»ƒæ€»è½®æ•°ã€‚"},
    },
    "max_grad_norm": {
        "en": {"label": "âœ‚ï¸ Maximum gradient norm", "info": "Norm for gradient clipping."},
        "zh": {"label": "âœ‚ï¸ æœ€å¤§æ¢¯åº¦èŒƒæ•°", "info": "ç”¨äºæ¢¯åº¦è£å‰ªçš„èŒƒæ•°ã€‚"},
    },
    "max_samples": {
        "en": {"label": "ğŸ§® Max samples", "info": "Maximum samples per dataset."},
        "zh": {"label": "ğŸ§® æœ€å¤§æ ·æœ¬æ•°", "info": "æ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•°ã€‚"},
    },
    "compute_type": {
        "en": {"label": "âœ¨ Compute type", "info": "Whether to use mixed precision training."},
        "zh": {"label": "âœ¨ è®¡ç®—ç±»å‹", "info": "æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒã€‚"},
    },
    "cutoff_len": {
        "en": {"label": "ğŸ—œï¸ Cutoff length", "info": "Max tokens in input sequence."},
        "zh": {"label": "ğŸ—œï¸ æˆªæ–­é•¿åº¦", "info": "è¾“å…¥åºåˆ—åˆ†è¯åçš„æœ€å¤§é•¿åº¦ã€‚"},
    },
    "batch_size": {
        "en": {"label": "ğŸ§º Batch size", "info": "Number of samples processed on each GPU."},
        "zh": {"label": "ğŸ§º æ‰¹å¤„ç†å¤§å°", "info": "æ¯ä¸ª GPU å¤„ç†çš„æ ·æœ¬æ•°é‡ã€‚"},
    },
    "gradient_accumulation_steps": {
        "en": {"label": "ğŸ”— Gradient accumulation", "info": "Number of steps for gradient accumulation."},
        "zh": {"label": "ğŸ”— æ¢¯åº¦ç´¯ç§¯", "info": "æ¢¯åº¦ç´¯ç§¯çš„æ­¥æ•°ã€‚"},
    },
    "val_size": {
        "en": {"label": "ğŸ’¡ Val size", "info": "Proportion of data in the dev set."},
        "zh": {"label": "ğŸ’¡ éªŒè¯é›†æ¯”ä¾‹", "info": "éªŒè¯é›†å å…¨éƒ¨æ ·æœ¬çš„ç™¾åˆ†æ¯”ã€‚"},
    },
    "lr_scheduler_type": {
        "en": {"label": "ğŸ§° LR scheduler", "info": "Name of the learning rate scheduler."},
        "zh": {"label": "ğŸ§°	å­¦ä¹ ç‡è°ƒèŠ‚å™¨", "info": "å­¦ä¹ ç‡è°ƒåº¦å™¨çš„åç§°ã€‚"},
    },
    "extra_tab": {"en": {"label": "Extra configurations"}, "zh": {"label": "å…¶å®ƒå‚æ•°è®¾ç½®"}},
    "logging_steps": {
        "en": {"label": "Logging steps", "info": "Number of steps between two logs."},
        "zh": {"label": "æ—¥å¿—é—´éš”", "info": "æ¯ä¸¤æ¬¡æ—¥å¿—è¾“å‡ºé—´çš„æ›´æ–°æ­¥æ•°ã€‚"},
    },
    "save_steps": {
        "en": {"label": "Save steps", "info": "Number of steps between two checkpoints."},
        "zh": {"label": "ä¿å­˜é—´éš”", "info": "æ¯ä¸¤æ¬¡æ–­ç‚¹ä¿å­˜é—´çš„æ›´æ–°æ­¥æ•°ã€‚"},
    },
    "eval_steps": {
        "en": {"label": "Validation steps", "info": "Number of steps between two evaluations."},
        "zh": {"label": "éªŒè¯æ­¥æ•°é—´éš”", "info": "æ¯ä¸¤æ¬¡è¯„ä¼°ä¹‹é—´çš„çš„æ›´æ–°æ­¥æ•°ã€‚"},
    },
    "warmup_steps": {
        "en": {"label": "Warmup steps", "info": "Number of steps used for warmup."},
        "zh": {"label": "é¢„çƒ­æ­¥æ•°", "info": "å­¦ä¹ ç‡é¢„çƒ­é‡‡ç”¨çš„æ­¥æ•°ã€‚"},
    },
    "neftune_alpha": {
        "en": {"label": "NEFTune alpha", "info": "Magnitude of noise adding to embedding vectors."},
        "zh": {"label": "NEFTune å™ªå£°å‚æ•°", "info": "åµŒå…¥å‘é‡æ‰€æ·»åŠ çš„å™ªå£°å¤§å°ã€‚"},
    },
    "extra_args": {
        "en": {"label": "Extra arguments", "info": "Extra arguments passed to the trainer in JSON format."},
        "zh": {"label": "é¢å¤–å‚æ•°", "info": "ä»¥ JSON æ ¼å¼ä¼ é€’ç»™è®­ç»ƒå™¨çš„é¢å¤–å‚æ•°ã€‚"},
    },
    "packing": {
        "en": {"label": "Pack sequences", "info": "Pack sequences into samples of fixed length."},
        "zh": {"label": "åºåˆ—æ‰“åŒ…", "info": "å°†åºåˆ—æ‰“åŒ…ä¸ºç­‰é•¿æ ·æœ¬ã€‚"},
    },
    "neat_packing": {
        "en": {"label": "Use neat packing", "info": "Avoid cross-attention between packed sequences."},
        "zh": {"label": "ä½¿ç”¨æ— æ±¡æŸ“æ‰“åŒ…", "info": "é¿å…æ‰“åŒ…åçš„åºåˆ—äº§ç”Ÿäº¤å‰æ³¨æ„åŠ›ã€‚"},
    },
    "train_on_prompt": {
        "en": {"label": "Train on prompt", "info": "Disable the label mask on the prompt (only for SFT)."},
        "zh": {"label": "å­¦ä¹ æç¤ºè¯", "info": "ä¸åœ¨æç¤ºè¯çš„éƒ¨åˆ†æ·»åŠ æ©ç ï¼ˆä»…é€‚ç”¨äº SFTï¼‰ã€‚"},
    },
    "mask_history": {
        "en": {"label": "Mask history", "info": "Train on the last turn only (only for SFT)."},
        "zh": {"label": "ä¸å­¦ä¹ å†å²å¯¹è¯", "info": "ä»…å­¦ä¹ æœ€åä¸€è½®å¯¹è¯ï¼ˆä»…é€‚ç”¨äº SFTï¼‰ã€‚"},
    },
    "resize_vocab": {
        "en": {"label": "Resize token embeddings", "info": "Resize the tokenizer vocab and the embedding layers."},
        "zh": {"label": "æ›´æ”¹è¯è¡¨å¤§å°", "info": "æ›´æ”¹åˆ†è¯å™¨è¯è¡¨å’ŒåµŒå…¥å±‚çš„å¤§å°ã€‚"},
    },
    "use_llama_pro": {
        "en": {"label": "Enable LLaMA Pro", "info": "Make the parameters in the expanded blocks trainable."},
        "zh": {"label": "ä½¿ç”¨ LLaMA Pro", "info": "ä»…è®­ç»ƒå—æ‰©å±•åçš„å‚æ•°ã€‚"},
    },
    "shift_attn": {
        "en": {"label": "Enable S^2 Attention", "info": "Use shift short attention proposed by LongLoRA."},
        "zh": {"label": "ä½¿ç”¨ S^2 Attention", "info": "ä½¿ç”¨ LongLoRA æå‡ºçš„ shift short attentionã€‚"},
    },
    "report_to": {
        "en": {"label": "Enable external logger", "info": "Use TensorBoard or wandb to log experiment."},
        "zh": {"label": "å¯ç”¨å¤–éƒ¨è®°å½•é¢æ¿", "info": "ä½¿ç”¨ TensorBoard æˆ– wandb è®°å½•å®éªŒã€‚"},
    },
    "freeze_tab": {"en": {"label": "Freeze tuning configurations"}, "zh": {"label": "éƒ¨åˆ†å‚æ•°å¾®è°ƒè®¾ç½®"}},
    "freeze_trainable_layers": {
        "en": {
            "label": "Trainable layers",
            "info": "Number of the last(+)/first(-) hidden layers to be set as trainable.",
        },
        "zh": {"label": "å¯è®­ç»ƒå±‚æ•°", "info": "æœ€æœ«å°¾ï¼ˆ+ï¼‰/æœ€å‰ç«¯ï¼ˆ-ï¼‰å¯è®­ç»ƒéšè—å±‚çš„æ•°é‡ã€‚"},
    },
    "freeze_trainable_modules": {
        "en": {
            "label": "Trainable modules",
            "info": "Name(s) of trainable modules. Use commas to separate multiple modules.",
        },
        "zh": {"label": "å¯è®­ç»ƒæ¨¡å—", "info": "å¯è®­ç»ƒæ¨¡å—çš„åç§°ã€‚ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”å¤šä¸ªåç§°ã€‚"},
    },
    "freeze_extra_modules": {
        "en": {
            "label": "Extra modules (optional)",
            "info": "Name(s) of modules apart from hidden layers to be set as trainable. Use commas to separate multiple modules.",
        },
        "zh": {"label": "é¢å¤–æ¨¡å—ï¼ˆéå¿…å¡«ï¼‰", "info": "é™¤éšè—å±‚ä»¥å¤–çš„å¯è®­ç»ƒæ¨¡å—åç§°ã€‚ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”å¤šä¸ªåç§°ã€‚"},
    },
    "lora_tab": {"en": {"label": "LoRA configurations"}, "zh": {"label": "LoRA å‚æ•°è®¾ç½®"}},
    "lora_rank": {
        "en": {"label": "LoRA rank", "info": "The rank of LoRA matrices."},
        "zh": {"label": "LoRA ç§©", "info": "LoRA çŸ©é˜µçš„ç§©å¤§å°ã€‚"},
    },
    "lora_alpha": {
        "en": {"label": "LoRA alpha", "info": "Lora scaling coefficient."},
        "zh": {"label": "LoRA ç¼©æ”¾ç³»æ•°", "info": "LoRA ç¼©æ”¾ç³»æ•°å¤§å°ã€‚"},
    },
    "lora_dropout": {
        "en": {"label": "LoRA dropout", "info": "Dropout ratio of LoRA weights."},
        "zh": {"label": "LoRA éšæœºä¸¢å¼ƒ", "info": "LoRA æƒé‡éšæœºä¸¢å¼ƒçš„æ¦‚ç‡ã€‚"},
    },
    "loraplus_lr_ratio": {
        "en": {"label": "LoRA+ LR ratio", "info": "The LR ratio of the B matrices in LoRA."},
        "zh": {"label": "LoRA+ å­¦ä¹ ç‡æ¯”ä¾‹", "info": "LoRA+ ä¸­ B çŸ©é˜µçš„å­¦ä¹ ç‡å€æ•°ã€‚"},
    },
    "create_new_adapter": {
        "en": {
            "label": "Create new adapter",
            "info": "Create a new adapter with randomly initialized weight upon the existing one.",
        },
        "zh": {"label": "æ–°å»ºé€‚é…å™¨", "info": "åœ¨ç°æœ‰çš„é€‚é…å™¨ä¸Šåˆ›å»ºä¸€ä¸ªéšæœºåˆå§‹åŒ–åçš„æ–°é€‚é…å™¨ã€‚"},
    },
    "use_rslora": {
        "en": {"label": "Use rslora", "info": "Use the rank stabilization scaling factor for LoRA layer."},
        "zh": {"label": "ä½¿ç”¨ rslora", "info": "å¯¹ LoRA å±‚ä½¿ç”¨ç§©ç¨³å®šç¼©æ”¾æ–¹æ³•ã€‚"},
    },
    "use_dora": {
        "en": {"label": "Use DoRA", "info": "Use weight-decomposed LoRA."},
        "zh": {"label": "ä½¿ç”¨ DoRA", "info": "ä½¿ç”¨æƒé‡åˆ†è§£çš„ LoRAã€‚"},
    },
    "use_pissa": {
        "en": {"label": "Use PiSSA", "info": "Use PiSSA method."},
        "zh": {"label": "ä½¿ç”¨ PiSSA", "info": "ä½¿ç”¨ PiSSA æ–¹æ³•ã€‚"},
    },
    "lora_target": {
        "en": {
            "label": "LoRA modules (optional)",
            "info": "Name(s) of modules to apply LoRA. Use commas to separate multiple modules.",
        },
        "zh": {"label": "LoRA ä½œç”¨æ¨¡å—ï¼ˆéå¿…å¡«ï¼‰", "info": "åº”ç”¨ LoRA çš„æ¨¡å—åç§°ã€‚ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”å¤šä¸ªåç§°ã€‚"},
    },
    "additional_target": {
        "en": {
            "label": "Additional modules (optional)",
            "info": "Name(s) of modules apart from LoRA layers to be set as trainable. Use commas to separate multiple modules.",
        },
        "zh": {"label": "é™„åŠ æ¨¡å—ï¼ˆéå¿…å¡«ï¼‰", "info": "é™¤ LoRA å±‚ä»¥å¤–çš„å¯è®­ç»ƒæ¨¡å—åç§°ã€‚ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”å¤šä¸ªåç§°ã€‚"},
    },
    "rlhf_tab": {"en": {"label": "RLHF configurations"}, "zh": {"label": "RLHF å‚æ•°è®¾ç½®"}},
    "pref_beta": {
        "en": {"label": "Beta value", "info": "Value of the beta parameter in the loss."},
        "zh": {"label": "Beta å‚æ•°", "info": "æŸå¤±å‡½æ•°ä¸­ beta è¶…å‚æ•°å¤§å°ã€‚"},
    },
    "pref_ftx": {
        "en": {"label": "Ftx gamma", "info": "The weight of SFT loss in the final loss."},
        "zh": {"label": "Ftx gamma", "info": "æŸå¤±å‡½æ•°ä¸­ SFT æŸå¤±çš„æƒé‡å¤§å°ã€‚"},
    },
    "pref_loss": {
        "en": {"label": "Loss type", "info": "The type of the loss function."},
        "zh": {"label": "æŸå¤±ç±»å‹", "info": "æŸå¤±å‡½æ•°çš„ç±»å‹ã€‚"},
    },
    "reward_model": {
        "en": {"label": "Reward model", "info": "Adapter of the reward model in PPO training."},
        "zh": {"label": "å¥–åŠ±æ¨¡å‹", "info": "PPO è®­ç»ƒä¸­å¥–åŠ±æ¨¡å‹çš„é€‚é…å™¨è·¯å¾„ã€‚"},
    },
    "ppo_score_norm": {
        "en": {"label": "Score norm", "info": "Normalizing scores in PPO training."},
        "zh": {"label": "å¥–åŠ±æ¨¡å‹", "info": "PPO è®­ç»ƒä¸­å½’ä¸€åŒ–å¥–åŠ±åˆ†æ•°ã€‚"},
    },
    "ppo_whiten_rewards": {
        "en": {"label": "Whiten rewards", "info": "Whiten the rewards in PPO training."},
        "zh": {"label": "ç™½åŒ–å¥–åŠ±", "info": "PPO è®­ç»ƒä¸­å°†å¥–åŠ±åˆ†æ•°åšç™½åŒ–å¤„ç†ã€‚"},
    },
    "arg_save_btn": {"en": {"value": "Save arguments"}, "zh": {"value": "ä¿å­˜è®­ç»ƒå‚æ•°"}},
    "arg_load_btn": {"en": {"value": "Load arguments"}, "zh": {"value": "è½½å…¥è®­ç»ƒå‚æ•°"}},
    "start_btn": {"en": {"value": "Start"}, "zh": {"value": "å¼€å§‹"}},
    "stop_btn": {"en": {"value": "Abort"}, "zh": {"value": "ä¸­æ–­"}},
    "output_dir": {
        "en": {"label": "Output dir", "info": "Directory for saving results."},
        "zh": {"label": "è¾“å‡ºç›®å½•", "info": "ä¿å­˜ç»“æœçš„è·¯å¾„ã€‚"},
    },
    "config_path": {
        "en": {"label": "Config path", "info": "Path to config saving arguments."},
        "zh": {"label": "é…ç½®è·¯å¾„", "info": "ä¿å­˜è®­ç»ƒå‚æ•°çš„é…ç½®æ–‡ä»¶è·¯å¾„ã€‚"},
    },
    "device_count": {
        "en": {"label": "Device count", "info": "Number of devices available."},
        "zh": {"label": "è®¾å¤‡æ•°é‡", "info": "å½“å‰å¯ç”¨çš„è¿ç®—è®¾å¤‡æ•°ã€‚"},
    },
    "output_box": {"en": {"label": "Info Box", "value": "Ready."}, "zh": {"label": "ä¿¡æ¯æ ", "value": "å‡†å¤‡å°±ç»ªã€‚"}},
    "loss_viewer": {"en": {"label": "Loss"}, "zh": {"label": "æŸå¤±"}},
    "predict": {"en": {"label": "Save predictions"}, "zh": {"label": "ä¿å­˜é¢„æµ‹ç»“æœ"}},
    "infer_backend": {"en": {"label": "Inference engine"}, "zh": {"label": "æ¨ç†å¼•æ“"}},
    "infer_dtype": {"en": {"label": "Inference data type"}, "zh": {"label": "æ¨ç†æ•°æ®ç±»å‹"}},
    "load_btn": {"en": {"value": "Load model"}, "zh": {"value": "åŠ è½½æ¨¡å‹"}},
    "unload_btn": {"en": {"value": "Unload model"}, "zh": {"value": "å¸è½½æ¨¡å‹"}},
    "info_box": {
        "en": {"label": "Info", "value": "Model unloaded, please load a model first."},
        "zh": {"label": "ä¿¡æ¯æ ", "value": "æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹ã€‚"},
    },
    "role": {"en": {"label": "Role"}, "zh": {"label": "è§’è‰²"}},
    "system": {"en": {"placeholder": "System prompt (optional)"}, "zh": {"placeholder": "ç³»ç»Ÿæç¤ºè¯ï¼ˆéå¿…å¡«ï¼‰"}},
    "tools": {"en": {"placeholder": "Tools (optional)"}, "zh": {"placeholder": "å·¥å…·åˆ—è¡¨ï¼ˆéå¿…å¡«ï¼‰"}},
    "image": {"en": {"label": "ğŸ“· Image"}, "zh": {"label": "ğŸ“· å›¾åƒ"}},
    "video": {"en": {"label": "ğŸ“¹ Video (optional)"}, "zh": {"label": "ğŸ“¹ è§†é¢‘"}},
    "query": {"en": {"placeholder": "Input..."}, "zh": {"placeholder": "è¾“å…¥..."}},
    "chat_btn": {"en": {"value": "ğŸ’¬ Chat"}, "zh": {"value": "ğŸ’¬ å¯¹è¯"}},
    "max_length": {"en": {"label": "Maximum length"}, "zh": {"label": "æœ€å¤§é•¿åº¦"}},
    "max_new_tokens": {"en": {"label": "Maximum new tokens"}, "zh": {"label": "æœ€å¤§ç”Ÿæˆé•¿åº¦"}},
    "top_p": {"en": {"label": "ğŸ“Š Top-p"}, "zh": {"label": "ğŸ“Š Top-p é‡‡æ ·å€¼"}},
    "temperature": {"en": {"label": "ğŸŒ¡ï¸ Temperature"}, "zh": {"label": "ğŸŒ¡ï¸ æ¸©åº¦ç³»æ•°"}},
    "clear_btn": {"en": {"value": "Clear history"}, "zh": {"value": "æ¸…ç©ºå†å²"}},
    "export_size": {
        "en": {"label": "Max shard size (GB)", "info": "The maximum size for a model file."},
        "zh": {"label": "æœ€å¤§åˆ†å—å¤§å°ï¼ˆGBï¼‰", "info": "å•ä¸ªæ¨¡å‹æ–‡ä»¶çš„æœ€å¤§å¤§å°ã€‚"},
    },
    "export_quantization_bit": {
        "en": {"label": "Export quantization bit.", "info": "Quantizing the exported model."},
        "zh": {"label": "å¯¼å‡ºé‡åŒ–ç­‰çº§", "info": "é‡åŒ–å¯¼å‡ºæ¨¡å‹ã€‚"},
    },
    "export_quantization_dataset": {
        "en": {"label": "Export quantization dataset", "info": "The calibration dataset used for quantization."},
        "zh": {"label": "å¯¼å‡ºé‡åŒ–æ•°æ®é›†", "info": "é‡åŒ–è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ ¡å‡†æ•°æ®é›†ã€‚"},
    },
    "export_device": {
        "en": {"label": "Export device", "info": "Which device should be used to export model."},
        "zh": {"label": "å¯¼å‡ºè®¾å¤‡", "info": "å¯¼å‡ºæ¨¡å‹ä½¿ç”¨çš„è®¾å¤‡ç±»å‹ã€‚"},
    },
    "export_legacy_format": {
        "en": {"label": "Export legacy format", "info": "Do not use safetensors to save the model."},
        "zh": {"label": "å¯¼å‡ºæ—§æ ¼å¼", "info": "ä¸ä½¿ç”¨ safetensors æ ¼å¼ä¿å­˜æ¨¡å‹ã€‚"},
    },
    "export_dir": {
        "en": {"label": "Export dir", "info": "Directory to save exported model."},
        "zh": {"label": "å¯¼å‡ºç›®å½•", "info": "ä¿å­˜å¯¼å‡ºæ¨¡å‹çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚"},
    },
    "export_hub_model_id": {
        "en": {"label": "HF Hub ID (optional)", "info": "Repo ID for uploading model to Hugging Face hub."},
        "zh": {"label": "HF Hub IDï¼ˆéå¿…å¡«ï¼‰", "info": "ç”¨äºå°†æ¨¡å‹ä¸Šä¼ è‡³ Hugging Face Hub çš„ä»“åº“ IDã€‚"},
    },
    "export_btn": {"en": {"value": "Export"}, "zh": {"value": "å¼€å§‹å¯¼å‡º"}},
    "question_box": {
        "en": {"label": "ğŸ’­ Question", "info": "Enter your question here..."},
        "zh": {"label": "ğŸ’­ é—®é¢˜", "info": "åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜..."},
    },
    "seed_box": {"en": {"label": "ğŸ² Seed"}, "zh": {"label": "ğŸ² Seed"}},
    "question_type": {"en": {"label": "ğŸŒŸ Question type"}, "zh": {"label": "ğŸŒŸ é—®é¢˜ç±»å‹"}},
    "state_checkbox_group": {
        "en": {
            "label": "Chat State",
            "info": "check whether ready to chat or not",
            "choices": ["Question", "Image", "Video", "Model"],
        },
        "zh": {"label": "å¯¹è¯çŠ¶æ€", "info": "æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯¹è¯", "choices": ["é—®é¢˜", "å›¾åƒ", "è§†é¢‘", "æ¨¡å‹"]},
    },
    "ckpt_box": {"en": {"label": "Checkpoint Item"}, "zh": {"label": "æ£€æŸ¥ç‚¹"}},
}

ALERTS = {
    "err_conflict": {"en": "A process is in running, please abort it first.", "zh": "ä»»åŠ¡å·²å­˜åœ¨ï¼Œè¯·å…ˆä¸­æ–­è®­ç»ƒã€‚"},
    "err_exists": {"en": "You have loaded a model, please unload it first.", "zh": "æ¨¡å‹å·²å­˜åœ¨ï¼Œè¯·å…ˆå¸è½½æ¨¡å‹ã€‚"},
    "err_no_model": {"en": "Please select a model.", "zh": "è¯·é€‰æ‹©æ¨¡å‹ã€‚"},
    "err_no_cfg_path": {"en": "Please enter config path.", "zh": "è¯·è¾“å…¥é…ç½®æ–‡ä»¶çš„è·¯å¾„"},
    "err_no_path": {"en": "Model not found.", "zh": "æ¨¡å‹æœªæ‰¾åˆ°ã€‚"},
    "err_no_dataset": {"en": "Please choose a dataset.", "zh": "è¯·é€‰æ‹©æ•°æ®é›†ã€‚"},
    "err_no_adapter": {"en": "Please select an adapter.", "zh": "è¯·é€‰æ‹©é€‚é…å™¨ã€‚"},
    "err_no_output_dir": {"en": "Please provide output dir.", "zh": "è¯·å¡«å†™è¾“å‡ºç›®å½•ã€‚"},
    "err_failed": {"en": "Failed.", "zh": "è®­ç»ƒå‡ºé”™ã€‚"},
    "err_json_schema": {"en": "Invalid JSON schema.", "zh": "Json æ ¼å¼é”™è¯¯ã€‚"},
    "err_config_not_found": {"en": "Config file is not found.", "zh": "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ã€‚"},
    "warn_no_cuda": {"en": "CUDA environment was not detected.", "zh": "æœªæ£€æµ‹åˆ° CUDA ç¯å¢ƒã€‚"},
    "warn_output_dir_exists": {
        "en": "Output dir already exists, will resume training from here.",
        "zh": "è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œå°†ä»è¯¥æ–­ç‚¹æ¢å¤è®­ç»ƒã€‚",
    },
    "info_aborting_error": {"en": "Aborted error during non-trainning phase", "zh": "éè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸­æ–­å¤±è´¥"},
    "info_aborting": {"en": "Aborted, wait for terminating...", "zh": "è®­ç»ƒä¸­æ–­ï¼Œæ­£åœ¨ç­‰å¾…è¿›ç¨‹ç»“æŸâ€¦â€¦"},
    "info_aborted": {"en": "Aborted", "zh": "è®­ç»ƒä¸­æ–­"},
    "info_finished": {"en": "Finished.", "zh": "è®­ç»ƒå®Œæ¯•ã€‚"},
    "info_config_saved": {"en": "Arguments have been saved at: ", "zh": "è®­ç»ƒå‚æ•°å·²ä¿å­˜è‡³ï¼š"},
    "info_config_loaded": {"en": "Arguments have been restored.", "zh": "è®­ç»ƒå‚æ•°å·²è½½å…¥ã€‚"},
    "info_loading": {"en": "Loading model...", "zh": "åŠ è½½ä¸­â€¦â€¦"},
    "info_training": {"en": "Training...", "zh": "è®­ç»ƒä¸­â€¦â€¦"},
    "info_unloading": {"en": "Unloading model...", "zh": "å¸è½½ä¸­â€¦â€¦"},
    "info_loaded": {"en": "Model loaded!", "zh": "æ¨¡å‹å·²åŠ è½½ï¼"},
    "info_unloaded": {"en": "Model unloaded.", "zh": "æ¨¡å‹å·²å¸è½½ã€‚"},
    "info_unload_error": {"en": "Model has not been loaded yet", "zh": "æ¨¡å‹æœªåŠ è½½ï¼Œå¸è½½å¤±è´¥"},
    "info_exporting": {"en": "Exporting model...", "zh": "æ­£åœ¨å¯¼å‡ºæ¨¡å‹â€¦â€¦"},
    "info_exported": {"en": "Model exported.", "zh": "æ¨¡å‹å¯¼å‡ºå®Œæˆã€‚"},
    "info_query": {"en": "Please enter your question and then try again.", "zh": "è¯·è¾“å…¥ä½ çš„é—®é¢˜åé‡æ–°å°è¯•ã€‚"},
    "info_upload_file": {"en": "Please upload your image or video before chatting", "zh": "è¯·ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘åé‡æ–°å°è¯•"},
    "info_upload_model": {"en": "Please select and load your Model", "zh": "è¯·é€‰æ‹©å¹¶åŠ è½½æ‚¨çš„æ¨¡å‹"},
    "info_generating": {"en": "Generating...", "zh": "ç”Ÿæˆä¸­â€¦â€¦"},
    "info_generated": {"en": "Generated successfully", "zh": "ç”ŸæˆæˆåŠŸ"},
}
