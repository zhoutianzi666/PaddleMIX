# Copyright (c) 2025 PaddlePaddle Authors. All Rights Reserved.
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import gradio as gr
from model import ImageChatModel
from ollama import chat
import subprocess
import os
image_chat_model = ImageChatModel()


def start_ollama_service():
    try:
        subprocess.Popen(["ollama", "serve"])
        print("Ollama service started successfully")
        os.system("ollama ls")
    except Exception as e:
        print(f"Error starting Ollama service: {e}")
        
def analyze_image(image):
    if not image:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    prompt = "è¯·æè¿°è¿™ä¸ªåŠ¨æ¼«å›¾ç‰‡ï¼Œéœ€è¦1. æ¨æµ‹åŠ¨æ¼«æ˜¯å“ªä¸€éƒ¨ï¼›2. ç»™å‡ºå›¾ç‰‡çš„æ•´ä½“é£æ ¼ï¼›3.æè¿°å›¾åƒä¸­çš„ç»†èŠ‚ï¼Œå¹¶æ¨æµ‹å¯èƒ½çš„èƒŒæ™¯æ•…äº‹ã€‚"
    for analysis in image_chat_model.generate_description(image, prompt):
        yield analysis  # è¿”å›ä¸­é—´çŠ¶æ€æ¶ˆæ¯
        if "è¯·ç¨ç­‰ï¼Œæ­£åœ¨åˆ†æå›¾ç‰‡..." not in analysis:
            return analysis
            


def analyze_face(image):
    if not image:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    """åˆ†æé¢å®¹ç‰¹å¾"""
    image_prompt = "è¯·è¯¦ç»†æè¿°æ­¤äººçš„æ€§åˆ«ï¼Œé¢ç›¸ç‰¹å¾ï¼ŒåŒ…æ‹¬ç¾è²Œé•¿ç›¸ã€äº”å®˜ã€è¡¨æƒ…ã€é…é¥°ç­‰ç»†èŠ‚ï¼Œè¾“å‡ºä¸ºJSONæ ¼å¼,ä¸­æ–‡ã€‚"
    for analysis in image_chat_model.generate_description(image, image_prompt):
        yield analysis  # è¿”å›ä¸­é—´çŠ¶æ€æ¶ˆæ¯
        if "è¯·ç¨ç­‰ï¼Œæ­£åœ¨åˆ†æå›¾ç‰‡..." not in analysis:
            return analysis


def analyze_fortune(
    image, image_analysis, birthday, mbti_type, analysis_type, custom_question, progress=gr.Progress()
):
    """åˆ†æè¿åŠ¿"""
    if not image:
        return "è¯·å…ˆä¸Šä¼ ç…§ç‰‡"
    if not image_analysis:
        return "è¯·å…ˆç­‰å¾…å›¾ç‰‡åˆ†æç»“æœ"
    # progress(0, desc="æ­£åœ¨å¯åŠ¨ AI å‘½ç†å¸ˆ...")
    yield "åˆ†æä¸­..."

    # ç”Ÿæˆå‘½ç†åˆ†æ
    # progress(0.4, desc="ğŸ¯ æ­£åœ¨è§£è¯»å‘½ç†...")
    prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIå‘½ç†å¸ˆï¼Œæ“…é•¿å°†ç°ä»£å¿ƒç†å­¦ä¸ä¸œæ–¹ç„å­¦ç›¸ç»“åˆã€‚
    ## å›¾åƒåˆ†æ
    {image_analysis}
    ## ç”¨æˆ·ä¿¡æ¯
    - ç”Ÿæ—¥ï¼š{birthday}
    - MBTIï¼š{mbti_type}
    - åˆ†æç±»å‹ï¼š{analysis_type}
    - ç‰¹å®šé—®é¢˜ï¼š{custom_question if custom_question else "æ— "}
    
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯è¿›è¡Œåˆ†æï¼š
    1. ç»“åˆæ€§åˆ«ã€é¢ç›¸ç‰¹å¾å’ŒMBTIç»™å‡ºæ€§æ ¼è§£è¯»
    2. åŸºäºç”Ÿæ—¥å’Œå½“å‰æ—¶é—´ç»™å‡ºè¿åŠ¿é¢„æµ‹
    3. é’ˆå¯¹ç”¨æˆ·é€‰æ‹©çš„åˆ†æç±»å‹ç»™å‡ºå…·ä½“å»ºè®®
    4. å¦‚æœæœ‰ç‰¹å®šé—®é¢˜ï¼Œè¯·ç‰¹åˆ«å…³æ³¨ç›¸å…³æ–¹é¢
    
    æ³¨æ„ï¼šä¿æŒä¸“ä¸šæ€§çš„åŒæ—¶è¦é€‚å½“èå…¥è¶£å‘³æ€§ï¼Œæœ€åæ³¨æ˜"æœ¬ç»“æœä»…ä¾›å¨±ä¹"ã€‚
    """

    # progress(0.6, desc="âœ¨ æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–è§£è¯»...")
    stream = chat(
        model="deepseek-r1:32b",
        messages=[
            {
                "role": "user",
                "content": prompt,
            },
        ],
        stream=True,
    )

    result = ""
    for chunk in stream:
        result += chunk["message"]["content"]
        # progress(0.8, desc="ğŸ“ æ­£åœ¨æ¶¦è‰²ç»“æœ...")
        yield result + "\n\nâŒ› æ­£åœ¨ç”Ÿæˆä¸­ï¼Œè¯·ç¨å€™..."

    # progress(1.0, desc="âœ… ç”Ÿæˆå®Œæˆï¼")
    yield result


def analyze_traditional_texts(image):
    """è¯†åˆ«å›¾ç‰‡ä¸­çš„ç¹ä½“å­—"""
    if not image:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"

    prompt = "è¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„ç¹ä½“å­—ï¼Œå¹¶è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡è¾“å‡ºã€‚æ ¼å¼è¦æ±‚å’ŒåŸæ–‡æ ¼å¼ä¸€è‡´ã€‚è¾“å‡ºç®€ä½“å­—ã€‚"
    for analysis in image_chat_model.generate_description(image, prompt):
        yield analysis  # è¿”å›ä¸­é—´çŠ¶æ€æ¶ˆæ¯
        if "è¯·ç¨ç­‰ï¼Œæ­£åœ¨åˆ†æå›¾ç‰‡..." not in analysis:
            return analysis

def anime_creation(
    image, image_analysis, creation_type, poem_type, story_type, style, custom_prompt, progress=gr.Progress()
):
    """ç”Ÿæˆåˆ›ä½œå†…å®¹"""
    if not image:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"

    progress(0.2, desc="ğŸ¨ æ­£åœ¨æ„æ€åˆ›æ„...")
    if creation_type == "è¯—æ­Œç±»":
        req = f"è¯·åˆ›ä½œä¸€é¦–{poem_type}, éœ€è¦å–è¯—æ­Œçš„åå­—"
    else:
        req = f"è¯·åˆ›ä½œ{style}é£æ ¼çš„{story_type}ï¼Œéœ€è¦å–ç« èŠ‚å"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªäº†è§£åŠ¨æ¼«ï¼Œå¯Œæœ‰æ‰æƒ…çš„ä½œå®¶ï¼Œèƒ½æ ¹æ®å›¾ç‰‡æè¿°å’Œåˆ›ä½œè¦æ±‚è¿›è¡Œåˆ›ä½œ
    ## å›¾ç‰‡æè¿°
    {image_analysis}
    ## åˆ›ä½œè¦æ±‚
    1. {req}
    2. å†…å®¹ä¸Šè´´åˆå›¾ç‰‡æè¿°ï¼Œåˆ›ä½œé£æ ¼è´´åˆå›¾ç‰‡çš„é£æ ¼ï¼Œå°½å¯èƒ½æ¨æ–­å‡ºè¿™ä¸ªåŠ¨æ¼«æ˜¯ä»€ä¹ˆï¼Œäººç‰©æœ‰å“ªäº›
    3. å¦‚æœæœ‰è‡ªå®šä¹‰éœ€æ±‚ï¼š{custom_prompt}ï¼Œéœ€è¦æ»¡è¶³ï¼›æ²¡æœ‰ä¸éœ€è¦ã€‚
    """
    progress(0.4, desc="âœï¸ æ­£åœ¨åˆ›ä½œä¸­...")
    stream = chat(
        model="deepseek-r1:32b",
        messages=[
            {
                "role": "user",
                "content": prompt,
            },
        ],
        stream=True,
    )

    result = ""
    for chunk in stream:
        result += chunk["message"]["content"]
        yield result + "\n\nâŒ› åˆ›ä½œç«åŠ›å…¨å¼€ä¸­ï¼Œè¯·ç¨å€™..."

    yield result


def chat_with_texts(message, history, text_content, history_flag=True):
    """ä¸æ–‡æœ¬å†…å®¹è¿›è¡Œå¯¹è¯

    Args:
        message: å½“å‰ç”¨æˆ·æ¶ˆæ¯
        history: å¯¹è¯å†å²è®°å½•
        text_content: æ–‡æ¡£å†…å®¹

    Yields:
        str: æ¨¡å‹å“åº”å†…å®¹
    """
    # è¾“å…¥éªŒè¯
    if not text_content:
        yield "è¯·å…ˆä¸Šä¼ å›¾ç‰‡!"
        return

    try:
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡çŒ®è§£è¯»ä¸“å®¶ã€‚
        ## æ–‡æ¡£å†…å®¹
        {text_content}
        
        è¯·åŸºäºä»¥ä¸Šæ–‡æ¡£å†…å®¹å’Œå†å²èŠå¤©è®°å½•å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœé—®é¢˜è¶…å‡ºèŒƒå›´ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
        """

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å†å²å¯¹è¯
        if history_flag and len(history) > 0:
            for msg in history:
                messages.append({"role": msg["role"], "content": msg["content"]})

        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({"role": "user", "content": message})

        # è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯
        stream = chat(model="deepseek-r1:32b", messages=messages, stream=True)

        # å¤„ç†å“åº”æµ
        result = ""
        for chunk in stream:
            if not chunk["message"]["content"]:
                continue

            content = chunk["message"]["content"]
            if content == "<think>":
                result += "ğŸ¤”æ€è€ƒä¸­..."
                yield result
                continue
            if content == "</think>":
                result += "âœ¨æ€è€ƒå®Œæˆ!"
                yield result
                continue

            result += content
            yield result + "\n\nâŒ› æ­£åœ¨ç”Ÿæˆå›ç­”ï¼Œè¯·ç¨å€™..."

        yield result

    except Exception as e:
        yield f"å¯¹è¯å‡ºé”™: {str(e)}"


def setup_events(
    image_input,
    image_analysis,
    creation_type,
    story_group,
    poem_group,
    generate_btn,
    style_type_poem,
    style_type_story,
    style,
    custom_prompt,
    output_text,
):
    """è®¾ç½®UIç»„ä»¶çš„äº‹ä»¶å¤„ç†"""

    def update_groups(choice):
        if choice == "è¯—æ­Œç±»":
            return gr.update(visible=False), gr.update(visible=True)
        else:
            return gr.update(visible=True), gr.update(visible=False)

    # å½“å›¾ç‰‡ä¸Šä¼ æ—¶ï¼Œè‡ªåŠ¨åˆ†æå›¾ç‰‡
    image_input.change(fn=analyze_image, inputs=[image_input], outputs=[image_analysis])

    # å½“åˆ›ä½œç±»å‹æ”¹å˜æ—¶ï¼Œæ›´æ–°æ˜¾ç¤ºçš„é€‰é¡¹ç»„
    creation_type.change(fn=update_groups, inputs=[creation_type], outputs=[story_group, poem_group])


# tabs
def create_anime_creation_tab():
    """åˆ›å»ºåŠ¨æ¼«äºŒåˆ›æ ‡ç­¾é¡µ"""
    with gr.Tab("åŠ¨æ¼«äºŒåˆ›"):
        gr.Markdown("# ğŸ¨ é«˜èƒ½å›å¿†æ€ï¼ä¸ºä½ å–œæ¬¢çš„åŠ¨æ¼«ç”»é¢äºŒåˆ›ğŸš€")
        gr.Markdown(
            """
        ğŸ“– æœ¬é¡¹ç›®åŸºäºPaddleMIXå’ŒDeepSeek-R1å®ç°ï¼[âœ¨PaddleMIXâœ¨](https://github.com/PaddlePaddle/PaddleMIX) è®©æˆ‘ä»¬èƒ½å¤Ÿå¼€ç®±å³ç”¨è®¸å¤šSOTAæ¨¡å‹ï¼Œå¿«æ¥çœ‹çœ‹å¦‚ä½•å¿«é€Ÿæ•´åˆ Qwen2.5-VL å’Œ DeepSeek-R1ä¸ºæˆ‘ä»¬å–œæ¬¢çš„åŠ¨æ¼«åœºæ™¯è¿›è¡ŒäºŒåˆ›å§ï½
        
        ğŸ’¡ **ä½¿ç”¨æ–¹æ³•ï¼š** <br>
        1.ä¸Šä¼ å›¾ç‰‡ ï¼ˆæˆ–ç‚¹å‡»åº”ç”¨ä¸‹æ–¹Examplesï¼‰<br>
        2.é€‰æ‹©åˆ›ä½œç±»å‹ï¼ˆè¯—æ­Œ/æ•…äº‹ï¼‰<br>
        3.è¾“å…¥è¡¥å……ä¿¡æ¯ï¼ˆæ¯”å¦‚æ˜¯å“ªä¸€éƒ¨åŠ¨æ¼«ï¼Œè§’è‰²æ˜¯å“ªäº›ï¼ŒæœŸæœ›çš„å‰§æƒ…ç­‰ï¼‰<br>
        4.ç‚¹å‡»"å¼€å§‹åˆ›ä½œ"
                        
        ğŸ–Œï¸ DeepSeek-R1å‡­å€Ÿå…¶å¼ºå¤§çš„æ¨ç†èƒ½åŠ›èƒ½ä¸ºæˆ‘ä»¬çš„åˆ›ä½œæä¾›æ›´å¤šæ€è·¯ï¼Œå¿«æ¥ä½“éªŒä¸€ä¸‹å§ï½
        """
        )

        with gr.Row():
            with gr.Column():
                image_input = gr.Image(type="pil", label="ğŸ–¼ï¸ Step 1: ä¸Šä¼ åŠ¨æ¼«æµ·æŠ¥")
                image_analysis = gr.Textbox(label="å›¾ç‰‡æè¿°", interactive=False)

                with gr.Group() as creation_type_group:
                    creation_type = gr.Radio(choices=["è¯—æ­Œç±»", "æ•…äº‹ç±»"], label="ğŸ“ Step 2: é€‰æ‹©åˆ›ä½œç±»å‹", value="è¯—æ­Œç±»")

                with gr.Group() as poem_group:
                    style_type_poem = gr.Radio(choices=["äº”è¨€ç»å¥", "ä¸ƒè¨€å¾‹è¯—", "ç°ä»£è¯—"], label="âœ¨ Step 3: é€‰æ‹©è¯—æ­Œç±»å‹", value="ç°ä»£è¯—")

                with gr.Group(visible=False) as story_group:
                    style_type_story = gr.Radio(choices=["å¾®å°è¯´", "å‰§æœ¬å¤§çº²", "åˆ†é•œè„šæœ¬"], label="âœ¨ Step 3: é€‰æ‹©æ•…äº‹ç±»å‹", value="å¾®å°è¯´")
                    style = gr.Radio(
                        choices=["çƒ­è¡€", "æ²»æ„ˆ", "æ‚¬ç–‘", "å¤é£", "ç§‘å¹»", "æ—¥å¸¸"], label="ğŸ¨ Step 4: é€‰æ‹©åˆ›ä½œé£æ ¼", value="æ²»æ„ˆ"
                    )

            with gr.Column():
                custom_prompt = gr.Textbox(label="ğŸ’­ Step 4: åˆ›ä½œè¡¥å……ä¿¡æ¯ï¼ˆé€‰å¡«ï¼‰", placeholder="è¾“å…¥é¢å¤–çš„åˆ›ä½œè¦æ±‚ï¼ˆåŠ¨æ¼«åç§°ã€ä»»åŠ¡ã€æƒ…èŠ‚è¡¥å……ï¼‰")
                generate_btn = gr.Button("ğŸš€ Step 5: å¼€å§‹åˆ›ä½œ")
                progress_status = gr.HTML(
                    visible=False,
                    value="""
                    <div style="padding: 1rem; border-radius: 0.5rem; background-color: #f3f4f6; margin-bottom: 1rem;">
                        <p style="margin: 0; display: flex; align-items: center; gap: 0.5rem;">
                            <span style="display: inline-block; animation: spin 1s linear infinite;">âœ¨</span>
                            <span id="progress-message">æ­£åœ¨æ„æ€åˆ›æ„...</span>
                        </p>
                    </div>
                    """,
                )
                output_text = gr.Textbox(label="åˆ›ä½œç»“æœ", interactive=False)

        examples = gr.Examples(
            examples=[
                ["./examples/haizeiwang.jpeg"],
                ["./examples/xiamu.jpg"],
                ["./examples/nezha.jpg"],
            ],
            inputs=[image_input],
        )

        # è®¾ç½®äº‹ä»¶å¤„ç†
        setup_events(
            image_input,
            image_analysis,
            creation_type,
            story_group,
            poem_group,
            generate_btn,
            style_type_poem,
            style_type_story,
            style,
            custom_prompt,
            output_text,
        )

        generate_btn.click(
            fn=anime_creation,
            inputs=[
                image_input,
                image_analysis,
                creation_type,
                style_type_poem,
                style_type_story,
                style,
                custom_prompt,
            ],
            outputs=[output_text],
        )


def create_fortune_tab():
    """åˆ›å»ºAIå‘½ç†å¸ˆæ ‡ç­¾é¡µ"""
    with gr.Tab("AIå‘½ç†å¸ˆ"):
        gr.Markdown("# ğŸ”® AIè§£å‘½å¤§å¸ˆ")
        gr.Markdown(
            """
        ğŸ“– æœ¬é¡¹ç›®åŸºäºPaddleMIXå’ŒDeepSeek-R1 å®ç°ï¼[âœ¨PaddleMIXâœ¨](https://github.com/PaddlePaddle/PaddleMIX) è®©æˆ‘ä»¬èƒ½å¤Ÿå¼€ç®±å³ç”¨è®¸å¤šSOTAæ¨¡å‹ï¼Œ
        å¿«æ¥ä½“éªŒ Qwen2.5-VL çš„å›¾åƒè§£æèƒ½åŠ›å’Œ DeepSeek-R1 çš„æ¨ç†èƒ½åŠ›ï¼Œä¸ºä½ çš„äººç”Ÿè§£å¯†å§ï½
        
        ğŸ’¡ **ä½¿ç”¨æ–¹æ³•ï¼š** <br>
        1. ä¸Šä¼ ä¸€å¼ æ¸…æ™°çš„è‡ªæ‹ç…§ï¼ˆå»ºè®®åŠèº«ç…§ï¼‰<br>
        2. å¡«å†™æ‚¨çš„ç”Ÿæ—¥å’ŒMBTIç±»å‹(é€‰å¡«)<br>
        3. é€‰æ‹©æƒ³è¦äº†è§£çš„è¿åŠ¿ç±»å‹(é€‰å¡«)<br>
        4. å¯ä»¥è¾“å…¥å…·ä½“æƒ³é—®çš„é—®é¢˜(é€‰å¡«)<br>
        5. ç‚¹å‡»"å¼€å§‹è§£æ"è·å–ä¸ªæ€§åŒ–è§£è¯»
        
        ğŸ¯ DeepSeek-R1å‡­å€Ÿå…¶å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œç»“åˆç°ä»£å¿ƒç†å­¦ä¸ä¸œæ–¹ç„å­¦ï¼Œä¸ºä½ æä¾›ç‹¬ç‰¹çš„è§£è¯»ï½
        
        âš ï¸ æœ¬åŠŸèƒ½ä»…ä¾›å¨±ä¹ï¼Œè¯·ç†æ€§å¯¹å¾…åˆ†æç»“æœ
        """
        )

        with gr.Row():
            with gr.Column():
                image_input = gr.Image(type="pil", label="ğŸ¤³ Step 1: ä¸Šä¼ è‡ªæ‹ç…§ç‰‡")
                image_analysis = gr.Textbox(label="é¢å®¹åˆ†æ", interactive=False)
                birthday = gr.Textbox(label="ğŸ“… Step 2: è¾“å…¥ç”Ÿæ—¥(é€‰å¡«)", placeholder="æ ¼å¼ï¼šYYYY-MM-DD", value="")
                mbti_type = gr.Dropdown(
                    choices=[
                        "æ— ",
                        "INTJ",
                        "INTP",
                        "ENTJ",
                        "ENTP",
                        "INFJ",
                        "INFP",
                        "ENFJ",
                        "ENFP",
                        "ISTJ",
                        "ISFJ",
                        "ESTJ",
                        "ESFJ",
                        "ISTP",
                        "ISFP",
                        "ESTP",
                        "ESFP",
                    ],
                    label="ğŸ­ Step 3: é€‰æ‹©MBTIç±»å‹(é€‰å¡«)",
                    value="æ— "
                )
                analysis_type = gr.Radio(
                    choices=["æ•´ä½“è¿åŠ¿", "æ„Ÿæƒ…è¿åŠ¿", "äº‹ä¸šè´¢è¿", "å¥åº·è¿åŠ¿"], label="ğŸ”® Step 4: é€‰æ‹©åˆ†æç±»å‹", value="æ•´ä½“è¿åŠ¿"
                )
                custom_question = gr.Textbox(label="â“ Step 5: è¾“å…¥ç‰¹å®šé—®é¢˜(é€‰å¡«)", placeholder="æœ‰ä»€ä¹ˆç‰¹åˆ«æƒ³äº†è§£çš„é—®é¢˜å—ï¼Ÿ")

            with gr.Column():
                generate_btn = gr.Button("âœ¨ Step 6: å¼€å§‹è§£æ")
                output_text = gr.Textbox(label="åˆ›ä½œç»“æœ", interactive=True)

        # è®¾ç½®äº‹ä»¶å¤„ç†
        image_input.change(fn=analyze_face, inputs=[image_input], outputs=[image_analysis])

        examples = gr.Examples(
            examples=[
                ["./examples/renxiang.JPG"],
            ],
            inputs=[image_input],
        )
        
        generate_btn.click(
            fn=analyze_fortune,
            inputs=[image_input, image_analysis, birthday, mbti_type, analysis_type, custom_question],
            outputs=[output_text],
        )


def create_traditional_qa_tab():
    """åˆ›å»ºç¹ä½“å­—è¯†åˆ«é—®ç­”æ ‡ç­¾é¡µ"""
    with gr.Tab("ç¹ä½“æ–‡çŒ®é—®ç­”"):
        gr.Markdown("# ğŸ“š ç¹ä½“æ–‡çŒ®æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
        gr.Markdown(
            """
        ğŸ“– æœ¬é¡¹ç›®åŸºäºPaddleMIXå’ŒDeepSeek-R1 å®ç°ï¼[âœ¨PaddleMIXâœ¨](https://github.com/PaddlePaddle/PaddleMIX) è®©æˆ‘ä»¬èƒ½å¤Ÿå¼€ç®±å³ç”¨è®¸å¤šSOTAæ¨¡å‹ï¼Œ
        å¿«æ¥ä½“éªŒ Qwen2.5-VL çš„å›¾åƒè§£æèƒ½åŠ›å’Œ DeepSeek-R1 çš„æ¨ç†èƒ½åŠ›ï¼Œå¿«æ¥ä½“éªŒä¸€ä¸‹å§ï½
                    
        ğŸ’¡ **åŠŸèƒ½è¯´æ˜ï¼š** 
        1. ä¸Šä¼ å«æœ‰ç¹ä½“å­—çš„å›¾ç‰‡ï¼ˆæˆ–ä»ä¸‹æ–¹é€‰æ‹©ç¤ºä¾‹ï¼‰
        2. æœ¬åŠ©æ‰‹å°†è‡ªåŠ¨è¯†åˆ«ç¹ä½“å­—å¹¶è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
        3. ç„¶åä½ å¯ä»¥é’ˆå¯¹æ–‡çŒ®å†…å®¹è¿›è¡Œæé—®
                    
        PS: æ”¯æŒå¤šè½®é—®ç­”
        """
        )

        with gr.Row():
            with gr.Column():
                image_input = gr.Image(type="pil", label="ğŸ“š Step 1: ä¸Šä¼ ç¹ä½“æ–‡çŒ®å›¾ç‰‡")
                text_content = gr.Textbox(label="ğŸ“ Step 2: è¯†åˆ«ç»“æœï¼ˆç®€ä½“ä¸­æ–‡ï¼‰", interactive=True, lines=10)

            with gr.Column():
                gr.Markdown("ğŸ’¬ Step 3: å¼€å§‹æé—®")
                gr.ChatInterface(
                    chat_with_texts,
                    additional_inputs=[text_content],
                    type="messages",
                    chatbot=gr.Chatbot(height=500),
                    theme="ocean",
                    cache_examples=True,
                )

        # è®¾ç½®äº‹ä»¶å¤„ç†
        image_input.change(fn=analyze_traditional_texts, inputs=[image_input], outputs=[text_content])

        examples = gr.Examples(
            examples=[
                ["./examples/doc_1.png"],
                ["./examples/doc_2.png"],
                ["./examples/doc_3.png"],
            ],
            inputs=[image_input],
        )


def create_interface():
    """åˆ›å»ºä¸»ç•Œé¢"""
    with gr.Blocks(title="ğŸ¨ PaddleMIX å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ›æ„å·¥åŠ") as interface:
        gr.Markdown("# ğŸ¨ PaddleMIX å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ›æ„å·¥åŠ")

        with gr.Tabs():
            create_traditional_qa_tab()
            create_anime_creation_tab()
            create_fortune_tab()

    return interface


def main():
    """ä¸»å‡½æ•°"""
    interface = create_interface()
    interface.launch(server_name="10.67.188.11", server_port=8101, share=True)


if __name__ == "__main__":
    start_ollama_service()
    main()
