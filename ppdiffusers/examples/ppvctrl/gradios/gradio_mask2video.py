import os
import cv2
import subprocess
import gradio as gr
from utils import FeedbackManager, add_watermark, extract_first_frame, process_input_video

env = os.environ
env["CUDA_VISIBLE_DEVICES"] = "1"

def generate_masked_video(input_video, subject_prompt):
    tmp_path = os.path.dirname(input_video)
    masked_video_path = input_video.replace('.mp4', '_masked.mp4')
    mask_video_path = input_video.replace('.mp4', '_mask.mp4')
    sam_command = [
        "python", "ppdiffusers/examples/ppvctrl/anchor/extract_mask.py",
        "--sam2_config", "configs/sam2.1_hiera_l.yaml",
        "--sam2_checkpoint", "ppdiffusers/examples/ppvctrl/weights/sam2/sam2.1_hiera_large.pdparams",
        "--input_path", input_video,
        "--control_video_path", masked_video_path,
        "--mask_video_path", mask_video_path,
        "--prompt", subject_prompt
    ]
    subprocess.run(sam_command, check=True, cwd='/'.join(os.getcwd().split('/')[:-3]), env=env)
    return masked_video_path, mask_video_path

def cogvideox_5b_i2v_vctrl_process(
    masked_video,
    mask_video,
    first_mask_image_path,
    first_rgb_image_path,
    prompt,
    controlnet_seed,
    controlnet_num_inference_steps,
    controlnet_guidance_scale,
    controlnet_conditioning_scale,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame,
    use_controlnet
): 
    use_controlnet = True if use_controlnet == "yes" else False
    controlnet_command = [
        "python", "tools/controlnet_gradio.py",
        "--image_path", first_rgb_image_path,
        "--mask_path", first_mask_image_path,
        "--prompt", prompt,
        "--task", "mask",
        "--reverse_mask", "True",
        "--controlnet_seed", str(controlnet_seed),
        "--controlnet_num_inference_steps", str(controlnet_num_inference_steps),
        "--controlnet_guidance_scale", str(controlnet_guidance_scale),
        "--controlnet_conditioning_scale", str(controlnet_conditioning_scale)
    ]

    output_dir = "infer_outputs/mask2video/i2v"
    vctrl_command = [
        "python", "infer_cogvideox_i2v_vctrl_cli.py",
        "--pretrained_model_name_or_path", "paddlemix/cogvideox-5b-i2v-vctrl",
        "--vctrl_path", "weights/mask/vctrl_5b_i2v_mask.pdparams",
        "--vctrl_config", "vctrl_configs/cogvideox_5b_i2v_vctrl_config.json",
        "--control_video_path", masked_video,
        "--control_mask_video_path", mask_video,
        "--output_dir", output_dir,
        "--task", "mask",
        "--ref_image_path", first_rgb_image_path.replace('.jpg', '_controlnet.jpg') if use_controlnet else first_rgb_image_path,
        "--prompt_path", prompt,
        "--width", "720",
        "--height", "480",
        "--max_frame", str(max_frame),
        "--guidance_scale", str(guidance_scale),
        "--num_inference_steps", str(num_inference_steps),
        "--conditioning_scale", str(conditioning_scale),
    ]    
    if use_controlnet:
        subprocess.run(controlnet_command, check=True, env=env)
    subprocess.run(vctrl_command, check=True, env=env)
    return add_watermark(os.path.join(output_dir, "output.mp4")), os.path.join(output_dir, "origin_predict.mp4"), os.path.join(output_dir, "test_1.mp4"), first_rgb_image_path.replace('.jpg', '_controlnet.jpg') if use_controlnet else first_rgb_image_path

def cogvideox_5b_vctrl_process(
    masked_video,
    mask_video,
    first_rgb_image_path,
    prompt,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame,
    use_controlnet
):
    output_dir = "infer_outputs/mask2video/t2v"
    vctrl_command = [
        "python", "infer_cogvideox_t2v_vctrl_cli.py",
        "--pretrained_model_name_or_path", "paddlemix/cogvideox-5b-vctrl",
        "--vctrl_path", "weights/mask/vctrl_5b_t2v_mask.pdparams",
        "--vctrl_config", "vctrl_configs/cogvideox_5b_vctrl_config.json",
        "--control_video_path", masked_video,
        "--control_mask_video_path", mask_video,
        "--output_dir", output_dir,
        "--task", "mask",
        "--prompt_path", prompt,
        "--width", "720",  
        "--height", "480",
        "--max_frame", str(max_frame),
        "--guidance_scale", str(guidance_scale),
        "--num_inference_steps", str(num_inference_steps),
        "--conditioning_scale", str(conditioning_scale)
    ]
    subprocess.run(vctrl_command, check=True, env=env)
    return add_watermark(os.path.join(output_dir, "output.mp4")), os.path.join(output_dir, "origin_predict.mp4"), os.path.join(output_dir, "test_1.mp4"), first_rgb_image_path

def process(
    model,
    input_video,
    subject_prompt,
    prompt,
    controlnet_seed,
    controlnet_num_inference_steps,
    controlnet_guidance_scale,
    controlnet_conditioning_scale,
    num_inference_steps,
    conditioning_scale,
    guidance_scale,
    low_threshold,
    high_threshold,
    max_frame,
    use_controlnet
):
    input_video = process_input_video(input_video, task="mask", height=480, width=720)
    masked_video, mask_video = generate_masked_video(input_video, subject_prompt)
    first_mask_image_path = os.path.join(os.path.dirname(mask_video), 'first_mask_image.jpg')
    extract_first_frame(mask_video, first_mask_image_path)
    first_rgb_image_path = os.path.join(os.path.dirname(input_video), 'first_rgb_image.jpg')
    extract_first_frame(input_video, first_rgb_image_path, convert_rgb=True)

    if model == "cogvideox_5b_i2v_vctrl":
        output = cogvideox_5b_i2v_vctrl_process(
            masked_video,
            mask_video,
            first_mask_image_path,
            first_rgb_image_path,
            prompt,
            controlnet_seed,
            controlnet_num_inference_steps,
            controlnet_guidance_scale,
            controlnet_conditioning_scale,
            num_inference_steps,
            conditioning_scale,
            guidance_scale,
            low_threshold,
            high_threshold,
            max_frame,
            use_controlnet
        )
    elif model == "cogvideox_5b_vctrl":
        output = cogvideox_5b_vctrl_process(
            masked_video,
            mask_video,
            first_rgb_image_path,
            prompt,
            num_inference_steps,
            conditioning_scale,
            guidance_scale,
            low_threshold,
            high_threshold,
            max_frame,
            use_controlnet
        )
    else:
        raise ValueError(f"Invalid model name: {model}")

    current_output_dir = os.path.dirname(output[0])
    feedback_mgr.store_conversation(prompt, input_video, current_output_dir)
    feedback_mgr.mark_chat_complete()
    
    return output

def get_feedback_stats():
    """ä» FeedbackManager è·å–å½“å‰åé¦ˆæ•°æ®"""
    return f"{feedback_mgr.feedback_data['likes']} ğŸ‘ | {feedback_mgr.feedback_data['dislikes']} ğŸ‘"

feedback_mgr = FeedbackManager(os.path.join(os.path.dirname(os.path.abspath(__file__)), "feedback"))

block = gr.Blocks().queue()
with block:
    with gr.Row():
        gr.Markdown("## ğŸ¤– PP-VCtrl: Multimodal Video Editing (Mask) Demo")
    with gr.Row():
        gr.Markdown('ğŸ“š åŸå§‹æ¨¡å‹æ¥è‡ª [PaddleMIX](https://github.com/PaddlePaddle/PaddleMIX) ï¼ˆğŸŒŸ ä¸€ä¸ªåŸºäºé£æ¡¨PaddlePaddleæ¡†æ¶æ„å»ºçš„å¤šæ¨¡æ€å¤§æ¨¡å‹å¥—ä»¶ï¼‰')
    with gr.Row():
        gr.Markdown('PP-VCtrlæ˜¯ä¸€ä¸ªç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆæ§åˆ¶æ¨¡å‹ï¼š')
    with gr.Row():
        gr.Markdown('- å®ƒé€šè¿‡å¼•å…¥è¾…åŠ©æ¡ä»¶ç¼–ç å™¨ï¼Œå®ç°äº†å¯¹å„ç±»æ§åˆ¶ä¿¡å·çš„çµæ´»æ¥å…¥å’Œç²¾ç¡®æ§åˆ¶ï¼ŒåŒæ—¶ä¿æŒäº†é«˜æ•ˆçš„è®¡ç®—æ€§èƒ½')
    with gr.Row():
        gr.Markdown('- å®ƒå¯ä»¥é«˜æ•ˆåœ°åº”ç”¨åœ¨å„ç±»è§†é¢‘ç”Ÿæˆåœºæ™¯ï¼Œå°¤å…¶æ˜¯äººç‰©åŠ¨ç”»ã€åœºæ™¯è½¬æ¢ã€è§†é¢‘ç¼–è¾‘ç­‰éœ€è¦ç²¾ç¡®æ§åˆ¶çš„ä»»åŠ¡ã€‚')
    with gr.Row():
        gr.Markdown('**ï¼ˆåŸºäºMaskï¼‰è§†é¢‘ç¼–è¾‘çš„ä½¿ç”¨æ–¹æ³•ï¼š**')
    with gr.Row():
        gr.Markdown('- ä¸Šä¼ è§†é¢‘')
    with gr.Row():
        gr.Markdown('- è¾“å…¥subject promptï¼Œè¡¨ç¤ºæƒ³è¦æ›¿æ¢çš„è§†é¢‘ä¸­çš„ç›®æ ‡ï¼Œä¾‹å¦‚personï¼Œsky')
    with gr.Row():
        gr.Markdown('- è¾“å…¥promptæè¿°æ–°ç”Ÿæˆçš„è§†é¢‘ï¼Œå‚è€ƒæ ·ä¾‹ä¸­prompt')
    with gr.Row():
        gr.Markdown('- ç‚¹äº‘Runè¿›è¡Œç”Ÿæˆ')
    with gr.Row():
        gr.Markdown('- ç‚¹å‡»"ğŸ‘ Like"æˆ–"ğŸ‘ Dislike"å¯¹æ¨¡å‹å›ç­”è¿›è¡Œåé¦ˆ')
    with gr.Row():
        gr.Markdown('**æ³¨æ„äº‹é¡¹ï¼š**')
    with gr.Row():
        gr.Markdown('- è§†é¢‘è¦æ±‚ï¼šä¸ºè·å¾—æœ€å¥½çš„ç”Ÿæˆæ•ˆæœï¼Œå»ºè®®æä¾›720ï¼ˆå®½ï¼‰*480ï¼ˆé«˜ï¼‰è§†é¢‘ï¼Œè§†é¢‘é•¿åº¦åœ¨2s-5sï¼›è§†é¢‘åç§°ä¸èƒ½å­˜åœ¨ä¸­æ–‡ï¼Œç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·')
    with gr.Row():
        gr.Markdown('- subject promptè¦æ±‚ï¼šsubjectç›®æ ‡åº”åœ¨è§†é¢‘ä¸­å‡ºç°ï¼Œå¹¶ä¸”æœ€å¥½ä¸ºä¸»è¦ç›®æ ‡')
    with gr.Row():
        gr.Markdown('- promptè¦æ±‚ï¼šå’ŒåŸå§‹è§†é¢‘å…·æœ‰ä¸€å®šçš„ç›¸å…³æ€§ï¼›æè¿°å°½å¯èƒ½è¯¦ç»†ï¼Œå•è¯æ•°é‡åº”<80ä¸ªå•è¯')
    with gr.Row():
        gr.Markdown('- è¿è¡Œæ—¶é•¿ï¼šå¤§çº¦åœ¨20minï¼Œè¯·è€å¿ƒç­‰å¾…')
    with gr.Row():
        with gr.Column():
            input_video = gr.Video(label="Upload Video")
            subject_prompt = gr.Textbox(label="Subject Prompt")
            prompt = gr.Textbox(label="Prompt")
            model = gr.Dropdown(
                label="Select Model",
                choices=["cogvideox_5b_vctrl", "cogvideox_5b_i2v_vctrl"],
                value="cogvideox_5b_i2v_vctrl",
                interactive=True
            )
            use_controlnet = gr.Dropdown(
                label="Use ControlNet with â€˜cogvideox_5b_i2v_vctrlâ€™",
                choices=["yes", "no"],
                value="yes",
                interactive=True
            )
            run_button = gr.Button(value="Run")
            with gr.Accordion("Advanced options", open=False):
                controlnet_seed = gr.Slider(
                    label="controlnet Seed",
                    minimum=0,
                    maximum=100,
                    value=42,
                    step=1,
                )
                controlnet_num_inference_steps = gr.Slider(
                    label="controlnet Steps",
                    minimum=1,
                    maximum=100,
                    value=28,
                    step=1,
                )
                controlnet_guidance_scale = gr.Slider(
                    label="controlnet Guidance Scale",
                    minimum=0.1,
                    maximum=30.0,
                    value=7.0,
                    step=0.1,
                )
                controlnet_conditioning_scale = gr.Slider(
                    label="controlnet Conditioning Scale",
                    minimum=0.0,
                    maximum=1.0,
                    value=1.0,
                    step=0.1,
                )
                conditioning_scale = gr.Slider(
                    label="Control Strength",
                    minimum=0.0,
                    maximum=5.0,
                    value=1.0,
                    step=0.05,
                )
                low_threshold = gr.Slider(
                    label="Canny low threshold",
                    minimum=1,
                    maximum=255,
                    value=100,
                    step=1,
                )
                high_threshold = gr.Slider(
                    label="Canny high threshold",
                    minimum=1,
                    maximum=255,
                    value=200,
                    step=1,
                )
                num_inference_steps = gr.Slider(label="Steps", minimum=1, maximum=100, value=20, step=1)
                guidance_scale = gr.Slider(
                    label="Guidance Scale",
                    minimum=0.1,
                    maximum=30.0,
                    value=9.0,
                    step=0.1,
                )
                max_frame = gr.Slider(
                    label="Max frames",
                    minimum=1,
                    maximum=100,
                    value=49,
                    step=1,
                )
        with gr.Column():
            display_video = gr.Video(label="Presentation video")
            generated_video = gr.Video(label="Generated Video")
            compared_video = gr.Video(label="Compared Video")
            ref_image = gr.Image(label="Reference Image")
    
    with gr.Row():
        feedback_display = gr.Textbox(
            value=get_feedback_stats(),
            label="ğŸ“Š Feedback Stats",
            interactive=False
        )

    with gr.Row():
        like_button = gr.Button("ğŸ‘ Like")
        dislike_button = gr.Button("ğŸ‘ Dislike")
    
    like_button.click(
        fn=lambda: feedback_mgr.update_feedback("like"),
        outputs=feedback_display
    )
    dislike_button.click(
        fn=lambda: feedback_mgr.update_feedback("dislike"),
        outputs=feedback_display
    )
    
    ips = [
        model,
        input_video,
        subject_prompt,
        prompt,
        controlnet_seed,
        controlnet_num_inference_steps,
        controlnet_guidance_scale,
        controlnet_conditioning_scale,
        num_inference_steps,
        conditioning_scale,
        guidance_scale,
        low_threshold,
        high_threshold,
        max_frame,
        use_controlnet
    ]
    
    run_button.click(fn=process, inputs=ips, outputs=[display_video, generated_video, compared_video, ref_image])

block.launch(server_name="0.0.0.0", server_port=8233, share=True)